{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator, array_to_img, save_img\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "# import seaborn as sns\n",
    "from functools import partial\n",
    "# sns.set_context('notebook')\n",
    "# sns.set_style('white')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "# session = tf.compat.v1.Session(config=config)\n",
    "session = tf.compat.v1.InteractiveSession(config=config)\n",
    "\n",
    "\n",
    "# config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "#                                     # (nothing gets printed in Jupyter, only if you run it standalone)\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.2\n",
    "# config.gpu_options.allow_growth = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test GPU TensorFLow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "c = tf.matmul(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIRST IMAGE DETAILS: \n",
      "Class:  <class 'PIL.JpegImagePlugin.JpegImageFile'> \n",
      "File Format:  JPEG \n",
      "Image type:  RGB \n",
      "Image Size: (640, 480)\n",
      "\n",
      "*************** IMPORTING RGB Images ***************\n",
      "*************** Converting Images to Arrays ***************\n"
     ]
    }
   ],
   "source": [
    "my_dir = os.getcwd()  # grabs current work dir\n",
    "all_file_paths = os.listdir()  # grabs all items in current work dir\n",
    "\n",
    "data_path = [data for data in all_file_paths if 'traindata_pp' in data.lower()]  # searches for data folder and retrieves\n",
    "\n",
    "\n",
    "picture_folder_path = os.path.join(my_dir, data_path[0])  # joins data folder and current work dir to get picture path\n",
    "all_pictures = os.listdir(picture_folder_path)  # list of pictures names in folder\n",
    "\n",
    "picture_complete_path = [os.path.join(picture_folder_path, pic) for pic in\n",
    "                         all_pictures]  # complete path to each picture\n",
    "\n",
    "img_1 = load_img(picture_complete_path[0])\n",
    "print(\"FIRST IMAGE DETAILS:\", \"\\nClass: \", type(img_1), \"\\nFile Format: \", img_1.format,\n",
    "      \"\\nImage type: \", img_1.mode, '\\nImage Size:', img_1.size)\n",
    "print()\n",
    "\n",
    "Color_message = '*' * 15 + ' IMPORTING RGB Images ' + '*' * 15\n",
    "\n",
    "print(Color_message)\n",
    "rgb_scale_photos = [load_img(photo, color_mode='rgb') for photo in picture_complete_path] # RGB\n",
    "\n",
    "\n",
    "# print()\n",
    "\n",
    "array_message = '*' * 15 + ' Converting Images to Arrays ' + '*' * 15\n",
    "print(array_message)\n",
    "\n",
    "\n",
    "array_photo_list = [img_to_array(photo) for photo in rgb_scale_photos] # RGB\n",
    "del rgb_scale_photos\n",
    "\n",
    "X_train_all = np.asarray(array_photo_list)\n",
    "X_train_all[:, :,:,0] /= 255.0  # normalizes images\n",
    "del array_photo_list\n",
    "\n",
    "# del rgb_scale_photos, array_photo_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(X_train_all[0][:,:,0],cmap='gray')\n",
    "# plt.imshow(array_photo_list[0][:,:,:].astype(np.uint8))   #OK??????\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "copies = int(X_train_all.shape[0] / 1025)  # how many copies of original data set. Augmentiaton copies = copies- 1\n",
    "print(copies)\n",
    "\n",
    "# read in CSV as pandas DF\n",
    "df_y = pd.read_csv('TrainAnnotations.csv')\n",
    "\n",
    "# strip annotation column and convert to numpy\n",
    "Y_train_1_copy = df_y['annotation'].to_numpy()  # original data labels\n",
    "\n",
    "Y_train_all = [Y_train_1_copy for i in range(copies)]  # multiply data labels\n",
    "Y_train_all = np.asarray(Y_train_all)  # convert list of data labels into 2D array\n",
    "Y_train_all = Y_train_all.flatten()  # flatten 2D array into 1D array\n",
    "\n",
    "\n",
    "# index position describes numeric values\n",
    "y_labels = ['No Wilting', 'Leaflets folding inward at secondary pulvinus, no turgor loss in leaflets or petioles',\n",
    "            'Slight leaflet or petiole turgor loss in upper canopy', 'Moderate turgor loss in upper canopy',\n",
    "            'Severe turgor loss throughout canopy']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>  Histogram of Underlying Y Label Distribution </center>\n",
    "\n",
    "<center> Highly unbalanced </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_y.describe()\n",
    "# sns.distplot(Y_train_all, kde=False, bins=5)\n",
    "# plt.show()\n",
    "X_train_all[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DefaultConv2D = partial(keras.layers.Conv2D,kernel_size=3, activation='relu', padding=\"SAME\")\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    DefaultConv2D(filters=64, kernel_size=11, input_shape=[X_train_all[0].shape[0],X_train_all[0].shape[1], 3]),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    DefaultConv2D(filters=128),\n",
    "    DefaultConv2D(filters=128),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    DefaultConv2D(filters=256),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units=64, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Dense(units=32, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Dense(units=10, activation='softmax'),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 480, 640, 64)      23296     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 240, 320, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 240, 320, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 240, 320, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 120, 160, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 120, 160, 256)     295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 60, 80, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1228800)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                78643264  \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 79,185,962\n",
      "Trainable params: 79,185,770\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2613 samples, validate on 462 samples\n",
      "Epoch 1/25\n",
      "2613/2613 [==============================] - 163s 62ms/sample - loss: 2.1681 - accuracy: 0.3241 - val_loss: 2.3578 - val_accuracy: 0.2511\n",
      "Epoch 2/25\n",
      "2613/2613 [==============================] - 157s 60ms/sample - loss: 1.5659 - accuracy: 0.5040 - val_loss: 3.2366 - val_accuracy: 0.3506\n",
      "Epoch 3/25\n",
      "2613/2613 [==============================] - 153s 59ms/sample - loss: 1.3317 - accuracy: 0.5522 - val_loss: 4.6224 - val_accuracy: 0.5022\n",
      "Epoch 4/25\n",
      "2608/2613 [============================>.] - ETA: 0s - loss: 1.1934 - accuracy: 0.5790"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_all, Y_train_all, epochs=25, validation_split=0.15, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(12, 6))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_all[1025]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.distplot(Y_train_all[0:1025],kde = False,bins=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
