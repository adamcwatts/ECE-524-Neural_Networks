{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from functools import partial\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "# session = tf.compat.v1.Session(config=config)\n",
    "session = tf.compat.v1.InteractiveSession(config=config)\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"talk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ressizer(image_tensor):\n",
    "    dim = (299, 299)\n",
    "    resized  = cv2.resize(image_tensor, dim)\n",
    "    \n",
    "    print('Resized Dimensions : ',resized.shape)\n",
    "#     cv2.imshow(\"Resized image\", resized)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "    \n",
    "    return resized\n",
    "\n",
    "def cropper(image_tensor):\n",
    "    SIZE = 299\n",
    "\n",
    "    width, height  = image_tensor.shape[0:2]\n",
    "\n",
    "    reduce_pixel_count = (width - SIZE  , height - SIZE)\n",
    "\n",
    "    rng = np.random.default_rng()\n",
    "    startRow = rng.integers(0, high=reduce_pixel_count[0], endpoint=True)\n",
    "    startCol = rng.integers(0, high=reduce_pixel_count[1], endpoint=True)\n",
    "    endRow = reduce_pixel_count[0] - startRow\n",
    "    endCol = reduce_pixel_count[1] - startCol\n",
    "\n",
    "\n",
    "    cropped_image = image_tensor[startRow:width-endRow, startCol:height-endCol]\n",
    "   \n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dir = os.getcwd()  # grabs current work dir\n",
    "all_file_paths = os.listdir()  # grabs all items in current work dir\n",
    "\n",
    "FOLDER_TO_ACCESS = 'traindata_pp'\n",
    "data_path = [data for data in all_file_paths if FOLDER_TO_ACCESS in data.lower()]  # searches for data folder and retrieves\n",
    "train_folder_path = os.path.join(my_dir, data_path[0])  # joins data folder and current work dir to get picture path\n",
    "all_classifications = os.listdir(train_folder_path)  # list of classification fodlers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification 0 = 38.275% or 488 images\n",
      "Classification 1 = 25.804% or 329 images\n",
      "Classification 2 = 10.196% or 130 images\n",
      "Classification 3 = 10.275% or 131 images\n",
      "Classification 4 = 15.451% or 197 images\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_Train = pd.read_csv('TrainAnnotations.csv')\n",
    "df_Train['annotation_string']=df_Train['annotation'].astype('str') # for KERAS\n",
    "\n",
    "fig, axe = plt.subplots(figsize=(6, 6))\n",
    "bin_val = np.arange(0, 6, 1) - 0.5\n",
    "sns.distplot(df_Train['annotation'], kde=False, bins=bin_val)\n",
    "# plt.xlim(-0.1,4.1)\n",
    "plt.xticks(np.arange(0,5, 1))\n",
    "plt.ylabel(\"Test Set: Bin Count\", labelpad=10)\n",
    "plt.xlabel('Classification')\n",
    "plt.tight_layout()\n",
    "\n",
    "df_Train['annotation'].value_counts(normalize=True)\n",
    "\n",
    "string_print = []\n",
    "for i in range(5):\n",
    "    val = df_Train.annotation.value_counts(normalize=True, sort=False).iloc[i]*100\n",
    "    val_count = df_Train.annotation.value_counts(normalize=False, sort=False).iloc[i]\n",
    "    string_print.append(f'Classification {i} = {val:.3f}% or {val_count} images')\n",
    "print(*string_print, sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_classes = np.sort(df_Train.annotation.unique())  # unique values, sort from small to largest\n",
    "classification_weight = class_weight.compute_class_weight('balanced', my_classes,df_Train.annotation.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1020 validated image filenames belonging to 5 classes.\n",
      "Found 1020 validated image filenames belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# IM_ORIG = np.array([640, 480])\n",
    "# IM_SCALE = 2\n",
    "\n",
    "# IM = IM_ORIG / IM_SCALE\n",
    "# IM = [int(x) for x in np.append(IM, 3).tolist()]\n",
    "\n",
    "IM = (299, 299)  #Desired Image Dimension to work with\n",
    "# IM = (640, 480)\n",
    "\n",
    "# train_datagen = ImageDataGenerator(\n",
    "#     validation_split=0.2) # set validation split\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(shear_range=0.1,\n",
    "                                   zoom_range=0.25,\n",
    "                                   horizontal_flip=True,\n",
    "                                   rotation_range=25,\n",
    "                                   fill_mode = 'wrap',\n",
    "                                   preprocessing_function=cropper,\n",
    "                                   validation_split=0.2)\n",
    "# set validation split\n",
    "\n",
    "train_it = train_datagen.flow_from_dataframe(\n",
    "    df_Train,x_col='file_name', y_col='annotation_string',\n",
    "    directory = train_folder_path,\n",
    "    target_size = IM,\n",
    "    subset='training',\n",
    "    class_mode='sparse',\n",
    "    shuffle=True,\n",
    "    batch_size=28)\n",
    "\n",
    "validate_it = train_datagen.flow_from_dataframe(\n",
    "    df_Train,x_col='file_name', y_col='annotation_string',\n",
    "    directory = train_folder_path,\n",
    "    target_size = IM,\n",
    "    subset='training',\n",
    "    class_mode='sparse',\n",
    "    shuffle=True,\n",
    "    batch_size=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view_it = train_datagen.flow_from_dataframe(\n",
    "#     df_Train,x_col='file_name', y_col='annotation_string',\n",
    "#     directory = train_folder_path,\n",
    "#     target_size = IM,\n",
    "#     subset='training',\n",
    "#     class_mode='sparse',\n",
    "#     shuffle=True,\n",
    "#     batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = view_it.next()\n",
    "\n",
    "# view_test_image = batch[0][0].astype('uint8')\n",
    "# cv2.imshow('Augmented Image', view_test_image)\n",
    " \n",
    "# cv2.waitKey(0) # waits until a key is pressed\n",
    "# cv2.destroyAllWindows() # destroys the window showing image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cropper(view_test_image)\n",
    "# batch = view_it.next()\n",
    "# view_test_image = batch[0][0].astype('uint8')\n",
    "# cv2.imshow('Augmented Image: NO CROP', view_test_image)\n",
    "# cv2.waitKey(0) # waits until a key is pressed\n",
    "# cv2.destroyAllWindows() # destroys the window showing image\n",
    "\n",
    "# SIZE = 299\n",
    "\n",
    "# width, height  = view_test_image.shape[0:2]\n",
    "\n",
    "# reduce_pixel_count = (width - SIZE  , height - SIZE)\n",
    "\n",
    "# rng = np.random.default_rng()\n",
    "# startRow = rng.integers(0, high=reduce_pixel_count[0], endpoint=True)\n",
    "# startCol = rng.integers(0, high=reduce_pixel_count[1], endpoint=True)\n",
    "# endRow = reduce_pixel_count[0] - startRow\n",
    "# endCol = reduce_pixel_count[1] - startCol\n",
    "\n",
    "\n",
    "# cropped_image = view_test_image[startRow:width-endRow, startCol:height-endCol]\n",
    "# cropped_image.shape\n",
    "\n",
    "# cv2.imshow(\"Augmented Image: CROP\", cropped_image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# print(startRow, startCol, reduce_pixel_count[0], width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cv2.imshow(\"test\", train_it.next()[0][0].astype('uint8'))\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "# new_input = keras.Input(shape=IM)\n",
    "model.add(InceptionV3(include_top=False, input_shape=(299, 299, 3), weights=\"imagenet\", pooling='avg'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=5, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 2048)              21802784  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 10245     \n",
      "=================================================================\n",
      "Total params: 21,813,029\n",
      "Trainable params: 21,778,597\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'view_test_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-f583b4378318>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                     \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                     shuffle=True, initial_epoch=0)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\Competition_Project\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Competition_Project\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Competition_Project\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Competition_Project\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    704\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 706\u001b[1;33m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Competition_Project\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, standardize_function, shuffle, workers, use_multiprocessing, max_queue_size, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m         **kwargs)\n\u001b[0m\u001b[0;32m    953\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Competition_Project\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, standardize_function, workers, use_multiprocessing, max_queue_size, **kwargs)\u001b[0m\n\u001b[0;32m    745\u001b[0m     \u001b[1;31m# Since we have to know the dtype of the python generator when we build the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m     \u001b[1;31m# dataset, we have to look at a batch to infer the structure.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 747\u001b[1;33m     \u001b[0mpeek\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_peek_and_restore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    748\u001b[0m     \u001b[0massert_not_namedtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Competition_Project\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_peek_and_restore\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    954\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_peek_and_restore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 956\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    957\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_make_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Competition_Project\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     63\u001b[0m         index_array = self.index_array[self.batch_size * idx:\n\u001b[0;32m     64\u001b[0m                                        self.batch_size * (idx + 1)]\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Competition_Project\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[1;34m(self, index_array)\u001b[0m\n\u001b[0;32m    237\u001b[0m                 \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_random_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstandardize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m             \u001b[0mbatch_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[1;31m# optionally save augmented images to disk for debugging purposes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Competition_Project\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py\u001b[0m in \u001b[0;36mstandardize\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    702\u001b[0m         \"\"\"\n\u001b[0;32m    703\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing_function\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrescale\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrescale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-abc56e53cb8d>\u001b[0m in \u001b[0;36mcropper\u001b[1;34m(image_tensor)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mSIZE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m299\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mview_test_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mreduce_pixel_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mSIZE\u001b[0m  \u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mSIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'view_test_image' is not defined"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2\n",
    "history = model.fit(train_it,\n",
    "                    steps_per_epoch=train_it.n // train_it.batch_size,\n",
    "                    epochs=EPOCHS, verbose=1,class_weight = classification_weight,\n",
    "                    callbacks=None, validation_data=validate_it,\n",
    "                    validation_steps=None, max_queue_size=2,\n",
    "                    workers=1, use_multiprocessing=False,\n",
    "                    shuffle=True, initial_epoch=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(np.linspace(1,EPOCHS,EPOCHS), history.history['val_accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
